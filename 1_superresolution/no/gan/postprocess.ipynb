{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56354684-43ab-4869-871a-554b1b280283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "from model import *\n",
    "\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tcunet import Unet2D\n",
    "# from YourDataset import YourDataset  # Import your custom dataset here\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchinfo import summary\n",
    "import torchprofile\n",
    "\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(23)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "DTYPE = torch.float32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e507cc25-d636-493d-a1b5-9590f8267893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power(true, pred, inp):\n",
    "    BS, nt, nx, ny = true.shape\n",
    "    \n",
    "    # Compute the Fourier transforms and amplitude squared for both true and pred\n",
    "    fourier_true = torch.fft.fftn(true, dim=(-2, -1))\n",
    "    fourier_pred = torch.fft.fftn(pred, dim=(-2, -1))\n",
    "    fourier_inp  = torch.fft.fftn(inp , dim=(-2, -1))\n",
    "\n",
    "    # Get the squared amplitudes\n",
    "    amplitudes_true = torch.abs(fourier_true) #** 2\n",
    "    amplitudes_pred = torch.abs(fourier_pred) #** 2\n",
    "    amplitudes_inp = torch.abs(fourier_inp) #** 2\n",
    "\n",
    "    # Create the k-frequency grids\n",
    "    kfreq_y = torch.fft.fftfreq(ny) * ny\n",
    "    kfreq_x = torch.fft.fftfreq(nx) * nx\n",
    "    kfreq2D_x, kfreq2D_y = torch.meshgrid(kfreq_x, kfreq_y, indexing='ij')\n",
    "    \n",
    "    # Compute the wavenumber grid\n",
    "    knrm = torch.sqrt(kfreq2D_x ** 2 + kfreq2D_y ** 2).to(true.device)\n",
    "    \n",
    "    # Define the bins for the wavenumber\n",
    "    kbins = torch.arange(0.5, nx // 2 + 1, 1.0, device=true.device)\n",
    "    \n",
    "    # Digitize knrm to bin indices\n",
    "    knrm_flat = knrm.flatten()\n",
    "    bin_indices = torch.bucketize(knrm_flat, kbins)\n",
    "\n",
    "    # Reshape and flatten the amplitudes\n",
    "    amplitudes_true_flat = amplitudes_true.view(BS, nt, nx * ny)\n",
    "    amplitudes_pred_flat = amplitudes_pred.view(BS, nt, nx * ny)\n",
    "    amplitudes_inp_flat  = amplitudes_inp.view(BS, nt, nx * ny)\n",
    "\n",
    "    # Initialize Abins\n",
    "    Abins_true = torch.zeros((BS, nt, len(kbins) - 1), device=true.device)\n",
    "    Abins_pred = torch.zeros((BS, nt, len(kbins) - 1), device=pred.device)\n",
    "    Abins_inp  = torch.zeros((BS, nt, len(kbins) - 1), device= inp.device)\n",
    "\n",
    "    # Vectorized binning: sum up the values in each bin\n",
    "    for bin_idx in range(1, len(kbins)):\n",
    "        mask = (bin_indices == bin_idx).unsqueeze(0).unsqueeze(0)  # Create a mask for each bin\n",
    "        Abins_true[:, :, bin_idx - 1] = (amplitudes_true_flat * mask).sum(dim=-1) / mask.sum(dim=-1)\n",
    "        Abins_pred[:, :, bin_idx - 1] = (amplitudes_pred_flat * mask).sum(dim=-1) / mask.sum(dim=-1)\n",
    "        Abins_inp[:,  :, bin_idx - 1] = (amplitudes_inp_flat  * mask).sum(dim=-1) / mask.sum(dim=-1)\n",
    "\n",
    "    # Scale the binned amplitudes\n",
    "    scaling_factor = torch.pi * (kbins[1:] ** 2 - kbins[:-1] ** 2)\n",
    "    Abins_true *= scaling_factor\n",
    "    Abins_pred *= scaling_factor\n",
    "    Abins_inp  *= scaling_factor\n",
    "\n",
    "    return Abins_true, Abins_pred, Abins_inp\n",
    "\n",
    "def plot_power_spectrum(power_inp, power_true, power_pred, inp, true, pred, epoch, err):\n",
    "    f = 2\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(4*f, 1*f))\n",
    "\n",
    "    sample_id=8\n",
    "    t_id = 0\n",
    "    for i in range(1):\n",
    "        x = torch.arange(true.shape[-2]//2)\n",
    "        axes[0].loglog(x, power_true[sample_id,t_id], label='true', c='black')\n",
    "        axes[0].loglog(x, power_inp[sample_id,t_id], label='NO', c='blue')\n",
    "        axes[0].loglog(x, power_pred[sample_id,t_id], label='adv. NO', c='red')\n",
    "        # axes[i].set_title(f\"t: {0}\")\n",
    "        axes[0].set_xlabel(r'$k$')\n",
    "        if i==0:\n",
    "            axes[0].legend()\n",
    "        if i==0:\n",
    "            axes[0].set_ylabel(r'$P(k)$')\n",
    "    \n",
    "\n",
    "    inp_sample = inp[sample_id, t_id]\n",
    "    true_sample = true[sample_id, t_id]\n",
    "    pred_sample = pred[sample_id, t_id]\n",
    "    vmin, vmax = true_sample.min(), true_sample.max()\n",
    "    im1 = axes[1].imshow(true_sample, vmin=vmin, vmax=vmax, cmap=CMAP)\n",
    "    axes[1].set_title(\"True\")\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "\n",
    "    im = axes[2].imshow(inp_sample, vmin=vmin, vmax=vmax, cmap=CMAP)\n",
    "    axes[2].set_title(\"NO\")\n",
    "    axes[2].set_xticks([])\n",
    "    axes[2].set_yticks([])\n",
    "\n",
    "    im = axes[3].imshow(pred_sample, vmin=vmin, vmax=vmax, cmap=CMAP)\n",
    "    axes[3].set_title(\"adv NO\")\n",
    "    axes[3].set_xticks([])\n",
    "    axes[3].set_yticks([])\n",
    "    fig.colorbar(im1, ax=axes[3])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    fig.suptitle(f\"Epoch: {epoch}, MSE: {err:.2e}\", fontsize=22, y=1.2)\n",
    "    plt.savefig(f\"power_spectrum/{epoch}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def error_metric(inp, pred,true, epoch, Par, is_plot=True):\n",
    "    power_inp, power_true, power_pred = compute_power(inp, true, pred)\n",
    "    err = torch.mean( (torch.log(power_true)-torch.log(power_pred) )**2 )\n",
    "    f_err = torch.norm(true-pred, p=2)/torch.norm(true, p=2)\n",
    "    ref_err = torch.norm(true-inp, p=2)/torch.norm(true, p=2)\n",
    "    if is_plot:\n",
    "        plot_power_spectrum(power_inp.detach().cpu().numpy(), power_true.detach().cpu().numpy(), power_pred.detach().cpu().numpy(), inp.detach().cpu().numpy(), true.detach().cpu().numpy(), pred.detach().cpu().numpy(), epoch, err)\n",
    "    return err, f_err, ref_err\n",
    "\n",
    "\n",
    "# Define your custom loss function here\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, Par):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.Par = Par\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = (y_true - self.Par[\"out_shift\"])/self.Par[\"out_scale\"]\n",
    "        y_pred = (y_pred - self.Par[\"out_shift\"])/self.Par[\"out_scale\"]\n",
    "        loss = torch.norm(y_true-y_pred, p=2)/torch.norm(y_true, p=2)\n",
    "        return loss\n",
    "\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample = self.x[idx]\n",
    "        y_sample = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x_sample, y_sample = self.transform(x_sample, y_sample)\n",
    "\n",
    "        return x_sample, y_sample\n",
    "\n",
    "\n",
    "def preprocess(x,y):\n",
    "    # x,y - [bs, nt, nx, ny]\n",
    "\n",
    "    B,T,X,Y = x.shape\n",
    "    x = x.reshape(-1,1,X,Y)\n",
    "    y = y.reshape(-1,1,X,Y)\n",
    "\n",
    "    print(f\"x: {x.shape}\")\n",
    "    print(f\"y: {y.shape}\")\n",
    "\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1395df8-3ac9-47ce-a08c-ed1c5103033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "x: (380, 1, 128, 256)\n",
      "y: (380, 1, 128, 256)\n",
      "Val\n",
      "x: (30, 1, 128, 256)\n",
      "y: (30, 1, 128, 256)\n",
      "Test\n",
      "x: (30, 1, 128, 256)\n",
      "y: (30, 1, 128, 256)\n",
      "{'inp_shift': 0.031219482, 'inp_scale': 0.65286255, 'out_shift': 0.05078125, 'out_scale': 0.72265625, 'nf': 1}\n"
     ]
    }
   ],
   "source": [
    "temp=\"TRAIN\"\n",
    "x_train = np.load(f\"../{temp}_PRED.npy\")\n",
    "y_train = np.load(f\"../{temp}_TRUE.npy\")\n",
    "\n",
    "temp=\"VAL\"\n",
    "x_val = np.load(f\"../{temp}_PRED.npy\")\n",
    "y_val = np.load(f\"../{temp}_TRUE.npy\")\n",
    "\n",
    "temp=\"TEST\"\n",
    "x_test = np.load(f\"../{temp}_PRED.npy\")\n",
    "y_test = np.load(f\"../{temp}_TRUE.npy\")\n",
    "\n",
    "inp_min = np.min(x_train[:,0])\n",
    "inp_max = np.max(x_train[:,0])\n",
    "out_min = np.min(y_train[:,0])\n",
    "out_max = np.max(y_train[:,0])\n",
    "\n",
    "print(\"Train\")\n",
    "x_train, y_train = preprocess(x_train, y_train)\n",
    "print(\"Val\")\n",
    "x_val, y_val = preprocess(x_val, y_val)\n",
    "print(\"Test\")\n",
    "x_test, y_test = preprocess(x_test, y_test)\n",
    "\n",
    "Par = {}\n",
    "Par[\"inp_shift\"] = inp_min\n",
    "Par[\"inp_scale\"] = inp_max - inp_min\n",
    "Par[\"out_shift\"] = out_min\n",
    "Par[\"out_scale\"] = out_max - out_min\n",
    "Par[\"nf\"] = x_train.shape[1]\n",
    "\n",
    "# Create custom datasets\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "x_val_tensor   = torch.tensor(x_val,   dtype=torch.float32)\n",
    "y_val_tensor   = torch.tensor(y_val,   dtype=torch.float32)\n",
    "\n",
    "x_test_tensor  = torch.tensor(x_test,  dtype=torch.float32)\n",
    "y_test_tensor  = torch.tensor(y_test,  dtype=torch.float32)\n",
    "\n",
    "train_dataset = YourDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = YourDataset(x_val_tensor, y_val_tensor)\n",
    "test_dataset = YourDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Define data loaders\n",
    "train_batch_size = 50\n",
    "val_batch_size   = 50\n",
    "test_batch_size  = 50\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n",
    "print(Par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e58624b-1ab5-4ba9-aa7c-1b02e164ae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "GeneratorRRDB                                      [1, 1, 128, 256]          --\n",
      "├─Conv2d: 1-1                                      [1, 32, 128, 256]         320\n",
      "├─Sequential: 1-2                                  [1, 32, 128, 256]         --\n",
      "│    └─ResidualInResidualDenseBlock: 2-1           [1, 32, 128, 256]         --\n",
      "│    │    └─Sequential: 3-1                        [1, 32, 128, 256]         415,200\n",
      "│    └─ResidualInResidualDenseBlock: 2-2           [1, 32, 128, 256]         --\n",
      "│    │    └─Sequential: 3-2                        [1, 32, 128, 256]         415,200\n",
      "│    └─ResidualInResidualDenseBlock: 2-3           [1, 32, 128, 256]         --\n",
      "│    │    └─Sequential: 3-3                        [1, 32, 128, 256]         415,200\n",
      "│    └─ResidualInResidualDenseBlock: 2-4           [1, 32, 128, 256]         --\n",
      "│    │    └─Sequential: 3-4                        [1, 32, 128, 256]         415,200\n",
      "├─Conv2d: 1-3                                      [1, 32, 128, 256]         9,248\n",
      "├─Sequential: 1-4                                  [1, 1, 128, 256]          --\n",
      "│    └─Conv2d: 2-5                                 [1, 32, 128, 256]         9,248\n",
      "│    └─LeakyReLU: 2-6                              [1, 32, 128, 256]         --\n",
      "│    └─Conv2d: 2-7                                 [1, 1, 128, 256]          289\n",
      "====================================================================================================\n",
      "Total params: 1,679,905\n",
      "Trainable params: 1,679,905\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 55.05\n",
      "====================================================================================================\n",
      "Input size (MB): 0.13\n",
      "Forward/backward pass size (MB): 528.74\n",
      "Params size (MB): 6.72\n",
      "Estimated Total Size (MB): 535.60\n",
      "====================================================================================================\n",
      "FLOPs: 1.10098e+11\n"
     ]
    }
   ],
   "source": [
    "model = GeneratorRRDB(Par[\"nf\"], Par).to(device).to(torch.float32) #Unet2D(dim=16, Par=Par, dim_mults=(1, 2, 4, 8)).to(device).to(torch.float32)\n",
    "\n",
    "path_model = f'saved_models/best_model.pth'\n",
    "model.load_state_dict(torch.load(path_model))\n",
    "\n",
    "print(summary(model, input_size=(1,)+x_train.shape[1:] ) )\n",
    "\n",
    "# Adjust the dimensions as per your model's input size\n",
    "dummy_x = x_train_tensor[0:1].to(device)\n",
    "# dummy_t = t_train_tensor[0:1].to(device)\n",
    "dummy_input = dummy_x\n",
    "\n",
    "# Profile the model\n",
    "model.eval()\n",
    "flops = 2 * torchprofile.profile_macs(model, dummy_input)\n",
    "print(f\"FLOPs: {flops:.5e}\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = CustomLoss(Par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab1af3-0171-4339-96b1-397315001373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46afa8-a2c4-4a7f-a60e-2968fb6c8d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb216eb-d6ae-4639-8b57-efc1ab7918f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tcunet import Unet2D\n",
    "\n",
    "with open('../Par.pkl', 'rb') as f:\n",
    "    Par_no = pickle.load(f)\n",
    "\n",
    "no = Unet2D(dim=16, Par=Par_no, dim_mults=(1, 2, 4, 8)).to(device).to(torch.float32)\n",
    "path_model = '../models/best_model.pt'\n",
    "no.load_state_dict(torch.load(path_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad175b2-4261-4276-946d-606392ba2868",
   "metadata": {},
   "source": [
    "# Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f15da60-91a2-4ba9-b34e-70860ad5d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2804e49d-3a20-4967-889d-48e33216d75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.21941\n",
      "Inference time: 0.01355\n",
      "Inference time: 0.01404\n",
      "Inference time: 0.01407\n",
      "Inference time: 0.01419\n",
      "Inference time: 0.01408\n",
      "Inference time: 0.01414\n",
      "Inference time: 0.01407\n",
      "Inference time: 0.01413\n",
      "Inference time: 0.01407\n",
      "Inference time: 0.01417\n",
      "Inference time: 0.01406\n",
      "Inference time: 0.01410\n",
      "Inference time: 0.01409\n",
      "Inference time: 0.01417\n",
      "\n",
      "mean: 0.014107966423034668\n"
     ]
    }
   ],
   "source": [
    "inference_time_ls = []\n",
    "\n",
    "inp_x = torch.rand(size=(1,2,128,256), dtype=DTYPE, device=device)\n",
    "inp_t = torch.rand(size=(1,), dtype=DTYPE, device=device)\n",
    "\n",
    "no.eval()\n",
    "model.eval()\n",
    "\n",
    "for i in range(15):\n",
    "    begin_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        no_pred = no(inp_x, inp_t)\n",
    "        no_gan  = model(no_pred)\n",
    "        # for x, y_true in test_data_loader:\n",
    "        #     y_pred = model(x.to(device))\n",
    "        #     break\n",
    "\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - begin_time\n",
    "    print(f\"Inference time: {inference_time:.5f}\")\n",
    "    inference_time_ls.append(inference_time)\n",
    "\n",
    "print()\n",
    "print(f\"mean: {np.mean(inference_time_ls[5:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab6836-d4ac-4f2c-b14f-dc4474dfb832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87962f-f9f9-4fd9-a5cd-0a3813c792a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe6a50ab-db54-4bdd-aa1a-38c6fe514f7e",
   "metadata": {},
   "source": [
    "# PeakVRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7a1fc9-f113-4944-be2d-2302cac32d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak VRAM (allocated): 0.2964 GB\n",
      "Peak VRAM (reserved) : 1.3044 GB\n",
      "Config: batch=1, dtype= torch.float32 , device= cuda\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = False  # keep runs reproducible\n",
    "\n",
    "no.eval()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Warmup\n",
    "with torch.no_grad():\n",
    "    no_pred = no(inp_x, inp_t)\n",
    "    no_gan  = model(no_pred)\n",
    "\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats() \n",
    "with torch.no_grad():\n",
    "    no_pred = no(inp_x, inp_t)\n",
    "    no_gan  = model(no_pred)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "# ---- Read peaks (bytes) and report in GB ----\n",
    "peak_alloc_GB   = torch.cuda.max_memory_allocated()  / 1e9\n",
    "peak_resvd_GB   = torch.cuda.max_memory_reserved()   / 1e9\n",
    "print(f\"Peak VRAM (allocated): {peak_alloc_GB:.4f} GB\")\n",
    "print(f\"Peak VRAM (reserved) : {peak_resvd_GB:.4f} GB\")\n",
    "print(\"Config: batch=1, dtype=\", DTYPE, \", device=\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67a751-606a-489e-afa7-d37cc776ab59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bb94e56-e27c-4267-97e4-a85a7b044e04",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7fc96cd-5cc6-4c08-8efb-c514719b3fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.8116e-01\n",
      " Val Loss: 1.8116e-01, spec err: 1.7461e-02, field err: 1.5506e-01, ref err: 1.2854e-01\n",
      "VAL_TRUE: (6, 5, 128, 256), DTYPE: float32\n",
      "VAL_PRED: (6, 5, 128, 256), DTYPE: float32\n",
      "Test Loss: 1.7635e-01\n",
      "TEST_TRUE: (6, 5, 128, 256), DTYPE: float32\n",
      "TEST_PRED: (6, 5, 128, 256), DTYPE: float32\n"
     ]
    }
   ],
   "source": [
    "y_true_ls = []\n",
    "y_pred_ls = []\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "spec_err = 0.0\n",
    "field_err = 0.0\n",
    "ref_err = 0.0\n",
    "plot_flag = False\n",
    "with torch.no_grad():\n",
    "    for x, y_true in val_loader:\n",
    "        if True:\n",
    "            y_pred = model(x.to(device))\n",
    "            loss   = criterion(y_pred, y_true.to(device))\n",
    "        s_err, f_err, r_err = error_metric(x.to(device), y_pred, y_true.to(device), 0, Par, plot_flag)\n",
    "        val_loss += loss\n",
    "        spec_err += s_err.item()\n",
    "        field_err += f_err.item()\n",
    "        ref_err += r_err.item()\n",
    "        y_true_ls.append(y_true.detach().cpu().numpy())\n",
    "        y_pred_ls.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "val_loss /= len(val_loader)\n",
    "spec_err /= len(val_loader)\n",
    "field_err /= len(val_loader)\n",
    "ref_err /= len(val_loader)\n",
    "print(f\"Val Loss: {val_loss:.4e}\")\n",
    "print(f\" Val Loss: {val_loss:.4e}, spec err: {spec_err:.4e}, field err: {field_err:.4e}, ref err: {ref_err:.4e}\" )\n",
    "\n",
    "VAL_TRUE = np.concatenate(y_true_ls, axis=0).reshape(-1, 5, 128, 256).astype(np.float32)\n",
    "VAL_PRED = np.concatenate(y_pred_ls, axis=0).reshape(-1, 5, 128, 256).astype(np.float32)\n",
    "\n",
    "print(f\"VAL_TRUE: {VAL_TRUE.shape}, DTYPE: {VAL_TRUE.dtype}\")\n",
    "print(f\"VAL_PRED: {VAL_PRED.shape}, DTYPE: {VAL_PRED.dtype}\")\n",
    "\n",
    "\n",
    "\n",
    "y_true_ls = []\n",
    "y_pred_ls = []\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for x, y_true in test_loader:\n",
    "        if True:\n",
    "            y_pred = model(x.to(device) )\n",
    "            loss   = criterion(y_pred, y_true.to(device))\n",
    "        test_loss += loss.item()\n",
    "        y_true_ls.append(y_true.detach().cpu().numpy())\n",
    "        y_pred_ls.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4e}\")\n",
    "\n",
    "TEST_TRUE = np.concatenate(y_true_ls, axis=0).reshape(-1, 5, 128, 256).astype(np.float32)\n",
    "TEST_PRED = np.concatenate(y_pred_ls, axis=0).reshape(-1, 5, 128, 256).astype(np.float32)\n",
    "\n",
    "print(f\"TEST_TRUE: {TEST_TRUE.shape}, DTYPE: {TEST_TRUE.dtype}\")\n",
    "print(f\"TEST_PRED: {TEST_PRED.shape}, DTYPE: {TEST_PRED.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "214257f1-8717-4f61-a33e-b5b830e50a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"TEST_TRUE.npy\", TEST_TRUE)\n",
    "np.save(\"TEST_PRED.npy\", TEST_PRED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
