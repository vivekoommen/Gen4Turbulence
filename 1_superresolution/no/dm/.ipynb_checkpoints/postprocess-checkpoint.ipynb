{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd889ba-15e5-406d-bf2c-889946c981bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from YourDataset import YourDataset  # Import your custom dataset here\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchinfo import summary\n",
    "import torchprofile\n",
    "\n",
    "from utils.architecture import Unet\n",
    "from utils.diffusion import ElucidatedDiffusion\n",
    "\n",
    "torch.manual_seed(23)\n",
    "import pickle\n",
    "\n",
    "DTYPE = torch.float32\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a0fa23-1efc-4d3a-babb-bd00f345b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metric(pred,true, Par):\n",
    "    #re-normalize\n",
    "    # true = true*Par['out_scale'] + Par['out_shift']\n",
    "    # true = true*Par['out_scale'] + Par['out_shift']\n",
    "    return torch.norm(true-pred, p=2)/torch.norm(true, p=2)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample = self.x[idx]\n",
    "        y_sample = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x_sample, y_sample = self.transform(x_sample, y_sample)\n",
    "\n",
    "        return x_sample, y_sample\n",
    "    \n",
    "def preprocess(x,y, Par):\n",
    "    x = sliding_window_view(x[:,Par['lb']-1:,:,:], window_shape=Par['lf'], axis=1 ).transpose(0,1,4,2,3).reshape(-1,Par['lf'],Par['nx'], Par['ny'])\n",
    "    y = sliding_window_view(y[:,Par['lb']-1:,:,:], window_shape=Par['lf'], axis=1 ).transpose(0,1,4,2,3).reshape(-1,Par['lf'],Par['nx'], Par['ny'])\n",
    "\n",
    "    print('x: ', x.shape)\n",
    "    print('y: ', y.shape)\n",
    "    print()\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8559f7c-6297-4136-8117-7dcb287bcfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading Time: 0.4s\n",
      "\n",
      "Train Dataset\n",
      "x:  (3980, 1, 128, 256)\n",
      "y:  (3980, 1, 128, 256)\n",
      "\n",
      "\n",
      "Validation Dataset\n",
      "x:  (480, 1, 128, 256)\n",
      "y:  (480, 1, 128, 256)\n",
      "\n",
      "\n",
      "Test Dataset\n",
      "x:  (480, 1, 128, 256)\n",
      "y:  (480, 1, 128, 256)\n",
      "\n",
      "Data Preprocess Time: 0.0s\n",
      "Par\n"
     ]
    }
   ],
   "source": [
    "res = 128\n",
    "begin_time = time.time()\n",
    "# inp = np.load(f\"/oscar/data/gk/voommen/no_diffusion/kolmogrov/res_{res}/matcho/Y_PRED.npy\") #low-fidelity\n",
    "# out = np.load(f\"/oscar/data/gk/voommen/no_diffusion/kolmogrov/res_{res}/matcho/Y_TRUE.npy\") #high-fidelity\n",
    "x_train = np.load(\"../TRAIN_PRED.npy\")\n",
    "y_train = np.load(\"../TRAIN_TRUE.npy\")\n",
    "\n",
    "x_val = np.load(\"../VAL_PRED.npy\")\n",
    "y_val = np.load(\"../VAL_TRUE.npy\")\n",
    "\n",
    "x_test = np.load(\"../TEST_PRED.npy\")\n",
    "y_test = np.load(\"../TEST_TRUE.npy\")\n",
    "print(f\"Data Loading Time: {time.time() - begin_time:.1f}s\")\n",
    "\n",
    "\n",
    "\n",
    "# # Train-Val-Test Split\n",
    "# idx1 = int(0.8 * inp.shape[0])\n",
    "# idx2 = int(0.9 * inp.shape[0])\n",
    "\n",
    "# x_train = inp[:idx1]\n",
    "# x_val   = inp[idx1:idx2]\n",
    "# x_test  = inp[idx2:]\n",
    "\n",
    "# y_train = out[:idx1]\n",
    "# y_val   = out[idx1:idx2]\n",
    "# y_test  = out[idx2:]\n",
    "\n",
    "\n",
    "\n",
    "inp_min = np.min(x_train)\n",
    "inp_max = np.max(x_train)\n",
    "out_min = np.min(y_train)\n",
    "out_max = np.max(y_train)\n",
    "\n",
    "\n",
    "\n",
    "Par = {\"inp_shift\" : torch.tensor(inp_min, dtype=DTYPE, device=device),\n",
    "       \"inp_scale\" : torch.tensor(inp_max - inp_min, dtype=DTYPE, device=device),\n",
    "       \"out_shift\" : torch.tensor(out_min, dtype=DTYPE, device=device),\n",
    "       \"out_scale\" : torch.tensor(out_max - out_min, dtype=DTYPE, device=device),\n",
    "       \"nx\"        : x_train.shape[2],\n",
    "       \"ny\"        : x_train.shape[3],\n",
    "       \"nf\"        : 1,\n",
    "       \"lb\"        : 1,\n",
    "       \"lf\"        : 1,\n",
    "       \"num_epochs\": 1000\n",
    "       }\n",
    "\n",
    "# Normalizing the data to [0,1]\n",
    "shift = Par['inp_shift'].detach().cpu().numpy()\n",
    "scale = Par['inp_scale'].detach().cpu().numpy()\n",
    "x_train = (x_train - shift)/scale\n",
    "x_val = (x_val - shift)/scale\n",
    "x_test = (x_test - shift)/scale\n",
    "\n",
    "shift = Par['out_shift'].detach().cpu().numpy()\n",
    "scale = Par['out_scale'].detach().cpu().numpy()\n",
    "y_train = (y_train - shift)/scale\n",
    "y_val = (y_val - shift)/scale\n",
    "y_test = (y_test - shift)/scale\n",
    "\n",
    "Par[\"sigma_data\"] = np.std(y_train)\n",
    "\n",
    "# Traj splitting\n",
    "begin_time = time.time()\n",
    "print('\\nTrain Dataset')\n",
    "x_train, y_train = preprocess(x_train, y_train, Par)\n",
    "print('\\nValidation Dataset')\n",
    "x_val, y_val = preprocess(x_val, y_val, Par)\n",
    "print('\\nTest Dataset')\n",
    "x_test, y_test = preprocess(x_test, y_test, Par)\n",
    "print(f\"Data Preprocess Time: {time.time() - begin_time:.1f}s\")\n",
    "\n",
    "Par.update({\"channels\"       : x_train.shape[1],\n",
    "            \"self_condition\" : True\n",
    "            })\n",
    "\n",
    "print(\"Par\")\n",
    "with open('Par.pkl', 'wb') as f:\n",
    "    pickle.dump(Par, f)\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "x_val_tensor   = torch.tensor(x_val,   dtype=torch.float32)\n",
    "y_val_tensor   = torch.tensor(y_val,   dtype=torch.float32)\n",
    "\n",
    "x_test_tensor  = torch.tensor(x_test,  dtype=torch.float32)\n",
    "y_test_tensor  = torch.tensor(y_test,  dtype=torch.float32)\n",
    "\n",
    "train_dataset = MyDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = MyDataset(x_val_tensor, y_val_tensor)\n",
    "test_dataset = MyDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Define data loaders\n",
    "train_batch_size = 100 #16\n",
    "val_batch_size   = 100\n",
    "test_batch_size  = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82e7fbd-f414-4c3a-9d2d-389c015fae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Unet                                     [1, 1, 128, 256]          --\n",
      "├─Conv2d: 1-1                            [1, 16, 128, 256]         1,584\n",
      "├─Sequential: 1-2                        [1, 64]                   --\n",
      "│    └─SinusoidalPosEmb: 2-1             [1, 16]                   --\n",
      "│    └─Linear: 2-2                       [1, 64]                   1,088\n",
      "│    └─GELU: 2-3                         [1, 64]                   --\n",
      "│    └─Linear: 2-4                       [1, 64]                   4,160\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─ModuleList: 2-5                   --                        --\n",
      "│    │    └─ResnetBlock: 3-1             [1, 16, 128, 256]         6,752\n",
      "│    │    └─ResnetBlock: 3-2             [1, 16, 128, 256]         6,752\n",
      "│    │    └─LinearAttention: 3-3         [1, 16, 128, 256]         9,264\n",
      "│    │    └─Sequential: 3-4              [1, 16, 64, 128]          1,040\n",
      "│    └─ModuleList: 2-6                   --                        --\n",
      "│    │    └─ResnetBlock: 3-5             [1, 16, 64, 128]          6,752\n",
      "│    │    └─ResnetBlock: 3-6             [1, 16, 64, 128]          6,752\n",
      "│    │    └─LinearAttention: 3-7         [1, 16, 64, 128]          9,264\n",
      "│    │    └─Sequential: 3-8              [1, 32, 32, 64]           2,080\n",
      "│    └─ModuleList: 2-7                   --                        --\n",
      "│    │    └─ResnetBlock: 3-9             [1, 32, 32, 64]           22,720\n",
      "│    │    └─ResnetBlock: 3-10            [1, 32, 32, 64]           22,720\n",
      "│    │    └─LinearAttention: 3-11        [1, 32, 32, 64]           17,504\n",
      "│    │    └─Sequential: 3-12             [1, 64, 16, 32]           8,256\n",
      "│    └─ModuleList: 2-8                   --                        --\n",
      "│    │    └─ResnetBlock: 3-13            [1, 64, 16, 32]           82,304\n",
      "│    │    └─ResnetBlock: 3-14            [1, 64, 16, 32]           82,304\n",
      "│    │    └─Attention: 3-15              [1, 64, 16, 32]           33,920\n",
      "│    │    └─Conv2d: 3-16                 [1, 128, 16, 32]          73,856\n",
      "├─ResnetBlock: 1-4                       [1, 128, 16, 32]          --\n",
      "│    └─Sequential: 2-9                   [1, 256]                  --\n",
      "│    │    └─SiLU: 3-17                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-18                 [1, 256]                  16,640\n",
      "│    └─Block: 2-10                       [1, 128, 16, 32]          --\n",
      "│    │    └─Conv2d: 3-19                 [1, 128, 16, 32]          147,584\n",
      "│    │    └─RMSNorm: 3-20                [1, 128, 16, 32]          128\n",
      "│    │    └─SiLU: 3-21                   [1, 128, 16, 32]          --\n",
      "│    │    └─Dropout: 3-22                [1, 128, 16, 32]          --\n",
      "│    └─Block: 2-11                       [1, 128, 16, 32]          --\n",
      "│    │    └─Conv2d: 3-23                 [1, 128, 16, 32]          147,584\n",
      "│    │    └─RMSNorm: 3-24                [1, 128, 16, 32]          128\n",
      "│    │    └─SiLU: 3-25                   [1, 128, 16, 32]          --\n",
      "│    │    └─Dropout: 3-26                [1, 128, 16, 32]          --\n",
      "│    └─Identity: 2-12                    [1, 128, 16, 32]          --\n",
      "├─Attention: 1-5                         [1, 128, 16, 32]          1,024\n",
      "│    └─RMSNorm: 2-13                     [1, 128, 16, 32]          128\n",
      "│    └─Conv2d: 2-14                      [1, 384, 16, 32]          49,152\n",
      "│    └─Attend: 2-15                      [1, 4, 512, 32]           --\n",
      "│    └─Conv2d: 2-16                      [1, 128, 16, 32]          16,512\n",
      "├─ResnetBlock: 1-6                       [1, 128, 16, 32]          --\n",
      "│    └─Sequential: 2-17                  [1, 256]                  --\n",
      "│    │    └─SiLU: 3-27                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-28                 [1, 256]                  16,640\n",
      "│    └─Block: 2-18                       [1, 128, 16, 32]          --\n",
      "│    │    └─Conv2d: 3-29                 [1, 128, 16, 32]          147,584\n",
      "│    │    └─RMSNorm: 3-30                [1, 128, 16, 32]          128\n",
      "│    │    └─SiLU: 3-31                   [1, 128, 16, 32]          --\n",
      "│    │    └─Dropout: 3-32                [1, 128, 16, 32]          --\n",
      "│    └─Block: 2-19                       [1, 128, 16, 32]          --\n",
      "│    │    └─Conv2d: 3-33                 [1, 128, 16, 32]          147,584\n",
      "│    │    └─RMSNorm: 3-34                [1, 128, 16, 32]          128\n",
      "│    │    └─SiLU: 3-35                   [1, 128, 16, 32]          --\n",
      "│    │    └─Dropout: 3-36                [1, 128, 16, 32]          --\n",
      "│    └─Identity: 2-20                    [1, 128, 16, 32]          --\n",
      "├─ModuleList: 1-7                        --                        --\n",
      "│    └─ModuleList: 2-21                  --                        --\n",
      "│    │    └─ResnetBlock: 3-37            [1, 128, 16, 32]          410,496\n",
      "│    │    └─ResnetBlock: 3-38            [1, 128, 16, 32]          410,496\n",
      "│    │    └─Attention: 3-39              [1, 128, 16, 32]          66,816\n",
      "│    │    └─Sequential: 3-40             [1, 64, 32, 64]           73,792\n",
      "│    └─ModuleList: 2-22                  --                        --\n",
      "│    │    └─ResnetBlock: 3-41            [1, 64, 32, 64]           106,944\n",
      "│    │    └─ResnetBlock: 3-42            [1, 64, 32, 64]           106,944\n",
      "│    │    └─LinearAttention: 3-43        [1, 64, 32, 64]           33,984\n",
      "│    │    └─Sequential: 3-44             [1, 32, 64, 128]          18,464\n",
      "│    └─ModuleList: 2-23                  --                        --\n",
      "│    │    └─ResnetBlock: 3-45            [1, 32, 64, 128]          28,896\n",
      "│    │    └─ResnetBlock: 3-46            [1, 32, 64, 128]          28,896\n",
      "│    │    └─LinearAttention: 3-47        [1, 32, 64, 128]          17,504\n",
      "│    │    └─Sequential: 3-48             [1, 16, 128, 256]         4,624\n",
      "│    └─ModuleList: 2-24                  --                        --\n",
      "│    │    └─ResnetBlock: 3-49            [1, 16, 128, 256]         9,584\n",
      "│    │    └─ResnetBlock: 3-50            [1, 16, 128, 256]         9,584\n",
      "│    │    └─LinearAttention: 3-51        [1, 16, 128, 256]         9,264\n",
      "│    │    └─Conv2d: 3-52                 [1, 16, 128, 256]         2,320\n",
      "├─ResnetBlock: 1-8                       [1, 16, 128, 256]         --\n",
      "│    └─Sequential: 2-25                  [1, 32]                   --\n",
      "│    │    └─SiLU: 3-53                   [1, 64]                   --\n",
      "│    │    └─Linear: 3-54                 [1, 32]                   2,080\n",
      "│    └─Block: 2-26                       [1, 16, 128, 256]         --\n",
      "│    │    └─Conv2d: 3-55                 [1, 16, 128, 256]         4,624\n",
      "│    │    └─RMSNorm: 3-56                [1, 16, 128, 256]         16\n",
      "│    │    └─SiLU: 3-57                   [1, 16, 128, 256]         --\n",
      "│    │    └─Dropout: 3-58                [1, 16, 128, 256]         --\n",
      "│    └─Block: 2-27                       [1, 16, 128, 256]         --\n",
      "│    │    └─Conv2d: 3-59                 [1, 16, 128, 256]         2,320\n",
      "│    │    └─RMSNorm: 3-60                [1, 16, 128, 256]         16\n",
      "│    │    └─SiLU: 3-61                   [1, 16, 128, 256]         --\n",
      "│    │    └─Dropout: 3-62                [1, 16, 128, 256]         --\n",
      "│    └─Conv2d: 2-28                      [1, 16, 128, 256]         528\n",
      "├─Conv2d: 1-9                            [1, 1, 128, 256]          17\n",
      "==========================================================================================\n",
      "Total params: 2,438,225\n",
      "Trainable params: 2,438,225\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 4.34\n",
      "==========================================================================================\n",
      "Input size (MB): 0.13\n",
      "Forward/backward pass size (MB): 481.31\n",
      "Params size (MB): 9.72\n",
      "Estimated Total Size (MB): 491.16\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:20<00:00,  1.56it/s]\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::arange\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::pow\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::pad\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::randn\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::full\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::log\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::cos\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::silu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::linalg_vector_norm\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::clamp_min\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand_as\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reciprocal\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs: 5.49957e+11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Network Architecture\n",
    "net = Unet(\n",
    "    dim = 16,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels = Par[\"channels\"],\n",
    "    self_condition = Par[\"self_condition\"],\n",
    "    flash_attn = True\n",
    ").to(device).to(torch.float32)\n",
    "print( summary(net, input_size=((1,)+x_train.shape[1:], (1,)) ) )\n",
    "\n",
    "model = ElucidatedDiffusion(net,\n",
    "                                channels = Par[\"channels\"],\n",
    "                                image_size_h=Par[\"nx\"],\n",
    "                                image_size_w=Par[\"ny\"],\n",
    "                                sigma_data=Par[\"sigma_data\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Wrapper(nn.Module):\n",
    "    def __init__(self, base, num_steps=32):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Must return a Tensor for torchprofile to trace properly.\n",
    "        y = self.base.sample(x, num_sample_steps=self.num_steps, seed=None)\n",
    "        # If your sample() returns a tuple/list, pick the tensor you want to count:\n",
    "        if isinstance(y, (tuple, list)):\n",
    "            y = y[0]\n",
    "        return y\n",
    "\n",
    "\n",
    "wrapper_model = Wrapper(model)\n",
    "\n",
    "# Adjust the dimensions as per your model's input size\n",
    "dummy_x = torch.randn(1, Par[\"channels\"], Par[\"nx\"], Par[\"ny\"],   dtype=DTYPE, device=device)\n",
    "dummy_input = dummy_x\n",
    "\n",
    "# Profile the model\n",
    "wrapper_model.eval()\n",
    "flops = 2 * torchprofile.profile_macs(wrapper_model, (dummy_x,))\n",
    "print(f\"FLOPs: {flops:.5e}\")\n",
    "\n",
    "# path_model = 'models/best_model.pt'\n",
    "# path_model = 'models/model_1230.pt'\n",
    "path_model = 'models/model_160.pt'\n",
    "model.load_state_dict(torch.load(path_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d861ef9-f975-4a38-8394-0c94a2a8d21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631c077-48ce-436e-b5c2-cc0149ec2078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682d379-6514-4b55-a5c2-c530aab52857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a254b1-6b2e-4eb3-b2ec-2308ea0f9571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "from matcho import Unet2D\n",
    "\n",
    "\n",
    "with open('../Par.pkl', 'rb') as f:\n",
    "    Par_no = pickle.load(f)\n",
    "\n",
    "no = Unet2D(dim=16, Par=Par_no, dim_mults=(1, 2, 4, 8)).to(device).to(torch.float32)\n",
    "path_model = '../models/best_model.pt'\n",
    "no.load_state_dict(torch.load(path_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42233ff0-5b4f-4d0e-a185-d86f17551ccf",
   "metadata": {},
   "source": [
    "# Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4ebbbe-844a-4cf7-be22-6a84f9975fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0560e90-be45-4430-94f9-f43c1a9c2436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.72485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.69770\n",
      "\n",
      "mean: 0.6970182180404663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inference_time_ls = []\n",
    "\n",
    "inp_x = torch.rand(size=(1,2,128,256), dtype=DTYPE, device=device)\n",
    "inp_t = torch.rand(size=(1,), dtype=DTYPE, device=device)\n",
    "\n",
    "no.eval()\n",
    "model.eval()\n",
    "\n",
    "for i in range(15):\n",
    "    begin_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        no_pred = no(inp_x, inp_t)\n",
    "        no_dm   = model.sample(no_pred, num_sample_steps=32)\n",
    "        # for l_fidel, h_fidel in test_data_loader:\n",
    "        #     y_pred = model.sample(l_fidel.to(device), num_sample_steps=32)\n",
    "        #     break\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - begin_time\n",
    "    print(f\"Inference time: {inference_time:.5f}\")\n",
    "    inference_time_ls.append(inference_time)\n",
    "\n",
    "print()\n",
    "print(f\"mean: {np.mean(inference_time_ls[5:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866482ed-e2d3-4ea7-9d35-c4acf0f4d798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6516620-e6db-4761-ad75-74f39697e209",
   "metadata": {},
   "source": [
    "# PeakVRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ddb9736-80d4-4c7c-8325-f1719e68c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.63it/s]\n",
      "sampling time step: 100%|██████████| 32/32 [00:00<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak VRAM (allocated): 0.3171 GB\n",
      "Peak VRAM (reserved) : 0.4048 GB\n",
      "Config: batch=1, dtype= torch.float32 , device= cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = False  # keep runs reproducible\n",
    "\n",
    "no.eval()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Warmup\n",
    "with torch.no_grad():\n",
    "    no_pred = no(inp_x, inp_t)\n",
    "    no_dm   = model.sample(no_pred, num_sample_steps=32)\n",
    "\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats() \n",
    "with torch.no_grad():\n",
    "    no_pred = no(inp_x, inp_t)\n",
    "    no_dm   = model.sample(no_pred, num_sample_steps=32)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "# ---- Read peaks (bytes) and report in GB ----\n",
    "peak_alloc_GB   = torch.cuda.max_memory_allocated()  / 1e9\n",
    "peak_resvd_GB   = torch.cuda.max_memory_reserved()   / 1e9\n",
    "print(f\"Peak VRAM (allocated): {peak_alloc_GB:.4f} GB\")\n",
    "print(f\"Peak VRAM (reserved) : {peak_resvd_GB:.4f} GB\")\n",
    "print(\"Config: batch=1, dtype=\", DTYPE, \", device=\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9724786-8404-4c68-8eb6-cecaccddfd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a52cc-af08-47ef-9f94-d0a125fc4c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97242a6f-a174-4501-9ea9-ac0508863512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 32/32 [00:06<00:00,  5.07it/s]\n",
      "sampling time step: 100%|██████████| 32/32 [00:06<00:00,  5.18it/s]\n",
      "sampling time step: 100%|██████████| 32/32 [00:06<00:00,  5.18it/s]\n",
      "sampling time step: 100%|██████████| 32/32 [00:06<00:00,  5.18it/s]\n",
      "sampling time step: 100%|██████████| 32/32 [00:05<00:00,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.9643e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "l_fidel_ls = []\n",
    "y_pred_ls = []\n",
    "y_true_ls = []\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for l_fidel, h_fidel in test_loader:\n",
    "        pred = model.sample(l_fidel.to(device), num_sample_steps=32)\n",
    "        loss   = error_metric(pred, h_fidel.to(device), Par)\n",
    "        test_loss += loss.item()\n",
    "        l_fidel_ls.append(l_fidel)\n",
    "        y_true_ls.append(h_fidel)\n",
    "        y_pred_ls.append(pred)\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df41729-4b3d-4513-8a11-173eefaf378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: (96, 5, 128, 256)\n",
      "y_pred: (96, 5, 128, 256)\n",
      "y_no  : (96, 5, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.cat(y_true_ls, dim=0).detach().cpu().numpy().reshape(-1, 5, Par[\"nx\"], Par[\"ny\"])\n",
    "y_pred = torch.cat(y_pred_ls, dim=0).detach().cpu().numpy().reshape(-1, 5, Par[\"nx\"], Par[\"ny\"])\n",
    "y_no   = torch.cat(l_fidel_ls, dim=0).detach().cpu().numpy().reshape(-1,5, Par[\"nx\"], Par[\"ny\"])\n",
    "\n",
    "# Renormalize from [0,1] to actual distribution\n",
    "y_true = y_true * Par['out_scale'].detach().cpu().numpy() + Par['out_shift'].detach().cpu().numpy()\n",
    "y_pred = y_pred * Par['out_scale'].detach().cpu().numpy() + Par['out_shift'].detach().cpu().numpy()\n",
    "y_no   = y_no   * Par['inp_scale'].detach().cpu().numpy() + Par['inp_shift'].detach().cpu().numpy()\n",
    "\n",
    "print(f\"y_true: {y_true.shape}\")\n",
    "print(f\"y_pred: {y_pred.shape}\")\n",
    "print(f\"y_no  : {y_no.shape}\")\n",
    "\n",
    "np.save(\"y_pred.npy\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760480ba-3ff5-4112-a900-6da5ce2b0793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
