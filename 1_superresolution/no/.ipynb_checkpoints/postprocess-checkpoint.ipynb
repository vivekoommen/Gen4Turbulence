{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56354684-43ab-4869-871a-554b1b280283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tcunet import Unet2D\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchinfo import summary\n",
    "import torchprofile\n",
    "\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(23)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "DTYPE = torch.float32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e507cc25-d636-493d-a1b5-9590f8267893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, Par):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.Par = Par\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = (y_true - self.Par[\"out_shift\"])/self.Par[\"out_scale\"]\n",
    "        y_pred = (y_pred - self.Par[\"out_shift\"])/self.Par[\"out_scale\"]\n",
    "        loss = torch.norm(y_true-y_pred, p=2)/torch.norm(y_true, p=2)\n",
    "        return loss\n",
    "\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, x, t, y, transform=None):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample = self.x[idx]\n",
    "        t_sample = self.t[idx]\n",
    "        y_sample = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x_sample, t_sample, y_sample = self.transform(x_sample, t_sample, y_sample)\n",
    "\n",
    "        return x_sample, t_sample, y_sample\n",
    "\n",
    "\n",
    "def preprocess(traj_i, traj_o, Par):\n",
    "    x = sliding_window_view(traj_i[:,:,:,:], window_shape=Par['lf'], axis=1 ).transpose(0,1,4,2,3).reshape(-1,Par['lf'],Par['nx'], Par['ny'])[:, [0,-1]] # BS, 2, nx, ny\n",
    "    y = sliding_window_view(traj_o[:,:,:,:], window_shape=Par['lf'], axis=1 ).transpose(0,1,4,2,3).reshape(-1,Par['lf'],Par['nx'], Par['ny'])            # BS, lf, nx, ny\n",
    "    t = np.linspace(0,1,Par['lf']).reshape(-1,1)\n",
    "\n",
    "    nt = y.shape[1]\n",
    "    n_samples = y.shape[0]\n",
    "\n",
    "    t = np.tile(t, [n_samples,1]).reshape(-1,)                         \n",
    "    x = np.repeat(x,nt, axis=0)                                  \n",
    "    y = y.reshape(y.shape[0]*y.shape[1],1,y.shape[2],y.shape[3])  \n",
    "\n",
    "    print('x: ', x.shape)\n",
    "    print('y: ', y.shape)\n",
    "    print('t: ', t.shape)\n",
    "    print()\n",
    "    return x,y,t\n",
    "\n",
    "def combined_scheduler(optimizer, total_epochs, warmup_epochs, last_epoch=-1):\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            return float(epoch + 1) / warmup_epochs\n",
    "        else:\n",
    "            return 0.5 * (1 + math.cos(math.pi * (epoch - warmup_epochs) / (total_epochs - warmup_epochs)))\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
    "\n",
    "def make_images(true, pred, epoch):\n",
    "    sample_id = -2\n",
    "    t_id = 0\n",
    "\n",
    "    CMAP = \"gray\"\n",
    "    VMIN = 0\n",
    "    VMAX = 255\n",
    "\n",
    "\n",
    "    T = true[sample_id, t_id].detach().cpu().numpy()*256\n",
    "    P = pred[sample_id, t_id].detach().cpu().numpy()*256\n",
    "\n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,5))\n",
    "    axes[0].imshow(T, cmap=CMAP, vmin=VMIN, vmax=VMAX)\n",
    "    axes[0].set_title(\"True\")\n",
    "    axes[1].imshow(P, cmap=CMAP, vmin=VMIN, vmax=VMAX)\n",
    "    axes[1].set_title(\"Pred\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    fig.suptitle(f\"Epoch: {epoch}\", fontsize=22, y=1.2)\n",
    "    plt.savefig(f\"images/{epoch}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1395df8-3ac9-47ce-a08c-ed1c5103033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_i: (1, 100, 128, 256)\n",
      "traj_o: (1, 100, 128, 256)\n",
      "Data Loading Time: 0.0s\n",
      "80 90\n",
      "\n",
      "Train Dataset\n",
      "x:  (380, 2, 128, 256)\n",
      "y:  (380, 1, 128, 256)\n",
      "t:  (380,)\n",
      "\n",
      "\n",
      "Validation Dataset\n",
      "x:  (30, 2, 128, 256)\n",
      "y:  (30, 1, 128, 256)\n",
      "t:  (30,)\n",
      "\n",
      "\n",
      "Test Dataset\n",
      "x:  (30, 2, 128, 256)\n",
      "y:  (30, 1, 128, 256)\n",
      "t:  (30,)\n",
      "\n",
      "Data Preprocess Time: 0.0s\n",
      "{'nx': 128, 'ny': 256, 'nf': 1, 'd_emb': 128, 'lb': 2, 'lf': 5, 'num_epochs': 50, 'inp_scale': 0.7561752, 'inp_shift': -0.0007444823, 'out_scale': 0.7265625, 'out_shift': 0.05078125, 't_shift': 0.0, 't_scale': 1.0}\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "traj_i = np.load(f\"../data/lr8_data.npy\").astype(np.float32)/256 #[nt, nx, ny]\n",
    "traj_i = np.expand_dims(traj_i, axis=0) #[1, nt, nx, ny]\n",
    "traj_o = np.load(f\"../data/hr_data.npy\").astype(np.float32)/256 #[nt, nx, ny]\n",
    "traj_o = np.expand_dims(traj_o, axis=0) #[1, nt, nx, ny]\n",
    "\n",
    "print(f\"traj_i: {traj_i.shape}\")\n",
    "print(f\"traj_o: {traj_o.shape}\")\n",
    "\n",
    "print(f\"Data Loading Time: {time.time() - begin_time:.1f}s\")\n",
    "\n",
    "\n",
    "nsamples = traj_i.shape[1]\n",
    "idx1 = int(0.8*nsamples)\n",
    "idx2 = int(0.9*nsamples)\n",
    "\n",
    "print(idx1, idx2)\n",
    "\n",
    "traj_i_train = traj_i[:, :idx1]\n",
    "traj_i_val   = traj_i[:, idx1:idx2]\n",
    "traj_i_test  = traj_i[:, idx2:]\n",
    "\n",
    "traj_o_train = traj_o[:, :idx1]\n",
    "traj_o_val   = traj_o[:, idx1:idx2]\n",
    "traj_o_test  = traj_o[:, idx2:]\n",
    "\n",
    "Par = {}\n",
    "# Par['nt'] = 100 \n",
    "Par['nx'] = traj_i_train.shape[2]\n",
    "Par['ny'] = traj_i_train.shape[3]\n",
    "Par['nf'] = 1\n",
    "Par['d_emb'] = 128\n",
    "\n",
    "Par['lb'] = 2\n",
    "Par['lf'] = 4+1\n",
    "# Par['temp'] = Par['nt'] - Par['lb'] - Par['lf'] + 2\n",
    "\n",
    "Par['num_epochs'] = 50 #50\n",
    "\n",
    "begin_time = time.time()\n",
    "print('\\nTrain Dataset')\n",
    "x_train, y_train, t_train = preprocess(traj_i_train, traj_o_train, Par)\n",
    "print('\\nValidation Dataset')\n",
    "x_val, y_val, t_val  = preprocess(traj_i_val, traj_o_val, Par)\n",
    "print('\\nTest Dataset')\n",
    "x_test, y_test, t_test  = preprocess(traj_i_test, traj_o_test, Par)\n",
    "print(f\"Data Preprocess Time: {time.time() - begin_time:.1f}s\")\n",
    "\n",
    "# sys.exit()\n",
    "\n",
    "t_min = np.min(t_train)\n",
    "t_max = np.max(t_train)\n",
    "\n",
    "Par['inp_scale'] = np.max(x_train) - np.min(x_train)\n",
    "Par['inp_shift'] = np.min(x_train)\n",
    "Par['out_scale'] = np.max(y_train) - np.min(y_train)\n",
    "Par['out_shift'] = np.min(y_train)\n",
    "Par['t_shift']   = t_min\n",
    "Par['t_scale']   = t_max - t_min\n",
    "\n",
    "with open('Par.pkl', 'wb') as f:\n",
    "    pickle.dump(Par, f)\n",
    "\n",
    "# sys.exit()\n",
    "#########################\n",
    "\n",
    "# Create custom datasets\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "t_train_tensor = torch.tensor(t_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "x_val_tensor   = torch.tensor(x_val,   dtype=torch.float32)\n",
    "t_val_tensor   = torch.tensor(t_val,   dtype=torch.float32)\n",
    "y_val_tensor   = torch.tensor(y_val,   dtype=torch.float32)\n",
    "\n",
    "x_test_tensor  = torch.tensor(x_test,  dtype=torch.float32)\n",
    "t_test_tensor  = torch.tensor(t_test,  dtype=torch.float32)\n",
    "y_test_tensor  = torch.tensor(y_test,  dtype=torch.float32)\n",
    "\n",
    "train_dataset = YourDataset(x_train_tensor, t_train_tensor, y_train_tensor)\n",
    "val_dataset = YourDataset(x_val_tensor, t_val_tensor, y_val_tensor)\n",
    "test_dataset = YourDataset(x_test_tensor, t_test_tensor, y_test_tensor)\n",
    "\n",
    "# Define data loaders\n",
    "train_batch_size = 20\n",
    "val_batch_size   = 20\n",
    "test_batch_size  = 20\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n",
    "print(Par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e58624b-1ab5-4ba9-aa7c-1b02e164ae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "Layer (type:depth-idx)                                  Output Shape              Param #\n",
      "=========================================================================================================\n",
      "Unet2D                                                  [1, 1, 128, 256]          --\n",
      "├─Conv2d: 1-1                                           [1, 16, 128, 256]         3,152\n",
      "├─Sequential: 1-2                                       [1, 64]                   --\n",
      "│    └─SinusoidalPosEmb: 2-1                            [1, 16]                   --\n",
      "│    └─Linear: 2-2                                      [1, 64]                   1,088\n",
      "│    └─GELU: 2-3                                        [1, 64]                   --\n",
      "│    └─Linear: 2-4                                      [1, 64]                   4,160\n",
      "├─ModuleList: 1-3                                       --                        --\n",
      "│    └─ModuleList: 2-5                                  --                        --\n",
      "│    │    └─ResnetBlock: 3-1                            [1, 16, 128, 256]         6,784\n",
      "│    │    └─ResnetBlock: 3-2                            [1, 16, 128, 256]         6,784\n",
      "│    │    └─Residual: 3-3                               [1, 16, 128, 256]         8,240\n",
      "│    │    └─Sequential: 3-4                             [1, 16, 64, 128]          1,040\n",
      "│    └─ModuleList: 2-6                                  --                        --\n",
      "│    │    └─ResnetBlock: 3-5                            [1, 16, 64, 128]          6,784\n",
      "│    │    └─ResnetBlock: 3-6                            [1, 16, 64, 128]          6,784\n",
      "│    │    └─Residual: 3-7                               [1, 16, 64, 128]          8,240\n",
      "│    │    └─Sequential: 3-8                             [1, 32, 32, 64]           2,080\n",
      "│    └─ModuleList: 2-7                                  --                        --\n",
      "│    │    └─ResnetBlock: 3-9                            [1, 32, 32, 64]           22,784\n",
      "│    │    └─ResnetBlock: 3-10                           [1, 32, 32, 64]           22,784\n",
      "│    │    └─Residual: 3-11                              [1, 32, 32, 64]           16,480\n",
      "│    │    └─Sequential: 3-12                            [1, 64, 16, 32]           8,256\n",
      "│    └─ModuleList: 2-8                                  --                        --\n",
      "│    │    └─ResnetBlock: 3-13                           [1, 64, 16, 32]           82,432\n",
      "│    │    └─ResnetBlock: 3-14                           [1, 64, 16, 32]           82,432\n",
      "│    │    └─Residual: 3-15                              [1, 64, 16, 32]           32,960\n",
      "│    │    └─Conv2d: 3-16                                [1, 128, 16, 32]          73,856\n",
      "├─ResnetBlock: 1-4                                      [1, 128, 16, 32]          --\n",
      "│    └─Sequential: 2-9                                  [1, 256]                  --\n",
      "│    │    └─SiLU: 3-17                                  [1, 64]                   --\n",
      "│    │    └─Linear: 3-18                                [1, 256]                  16,640\n",
      "│    └─Block: 2-10                                      [1, 128, 16, 32]          --\n",
      "│    │    └─Conv2d: 3-19                                [1, 128, 16, 32]          147,584\n",
      "│    │    └─GroupNorm: 3-20                             [1, 128, 16, 32]          256\n",
      "│    │    └─SiLU: 3-21                                  [1, 128, 16, 32]          --\n",
      "│    └─Block: 2-11                                      [1, 128, 16, 32]          --\n",
      "│    │    └─Conv2d: 3-22                                [1, 128, 16, 32]          147,584\n",
      "│    │    └─GroupNorm: 3-23                             [1, 128, 16, 32]          256\n",
      "│    │    └─SiLU: 3-24                                  [1, 128, 16, 32]          --\n",
      "│    └─Identity: 2-12                                   [1, 128, 16, 32]          --\n",
      "├─Residual: 1-5                                         [1, 128, 16, 32]          --\n",
      "│    └─PreNorm: 2-13                                    [1, 128, 16, 32]          --\n",
      "│    │    └─LayerNorm: 3-25                             [1, 128, 16, 32]          128\n",
      "│    │    └─Attention: 3-26                             [1, 128, 16, 32]          65,664\n",
      "├─ResnetBlock: 1-6                                      [1, 128, 16, 32]          --\n",
      "│    └─Sequential: 2-14                                 [1, 256]                  --\n",
      "│    │    └─SiLU: 3-27                                  [1, 64]                   --\n",
      "│    │    └─Linear: 3-28                                [1, 256]                  16,640\n",
      "│    └─Block: 2-15                                      [1, 128, 16, 32]          --\n",
      "│    │    └─Conv2d: 3-29                                [1, 128, 16, 32]          147,584\n",
      "│    │    └─GroupNorm: 3-30                             [1, 128, 16, 32]          256\n",
      "│    │    └─SiLU: 3-31                                  [1, 128, 16, 32]          --\n",
      "│    └─Block: 2-16                                      [1, 128, 16, 32]          --\n",
      "│    │    └─Conv2d: 3-32                                [1, 128, 16, 32]          147,584\n",
      "│    │    └─GroupNorm: 3-33                             [1, 128, 16, 32]          256\n",
      "│    │    └─SiLU: 3-34                                  [1, 128, 16, 32]          --\n",
      "│    └─Identity: 2-17                                   [1, 128, 16, 32]          --\n",
      "├─ModuleList: 1-7                                       --                        --\n",
      "│    └─ModuleList: 2-18                                 --                        --\n",
      "│    │    └─ResnetBlock: 3-35                           [1, 128, 16, 32]          410,752\n",
      "│    │    └─ResnetBlock: 3-36                           [1, 128, 16, 32]          410,752\n",
      "│    │    └─Residual: 3-37                              [1, 128, 16, 32]          65,920\n",
      "│    │    └─Sequential: 3-38                            [1, 64, 32, 64]           73,792\n",
      "│    └─ModuleList: 2-19                                 --                        --\n",
      "│    │    └─ResnetBlock: 3-39                           [1, 64, 32, 64]           107,072\n",
      "│    │    └─ResnetBlock: 3-40                           [1, 64, 32, 64]           107,072\n",
      "│    │    └─Residual: 3-41                              [1, 64, 32, 64]           32,960\n",
      "│    │    └─Sequential: 3-42                            [1, 32, 64, 128]          18,464\n",
      "│    └─ModuleList: 2-20                                 --                        --\n",
      "│    │    └─ResnetBlock: 3-43                           [1, 32, 64, 128]          28,960\n",
      "│    │    └─ResnetBlock: 3-44                           [1, 32, 64, 128]          28,960\n",
      "│    │    └─Residual: 3-45                              [1, 32, 64, 128]          16,480\n",
      "│    │    └─Sequential: 3-46                            [1, 16, 128, 256]         4,624\n",
      "│    └─ModuleList: 2-21                                 --                        --\n",
      "│    │    └─ResnetBlock: 3-47                           [1, 16, 128, 256]         9,616\n",
      "│    │    └─ResnetBlock: 3-48                           [1, 16, 128, 256]         9,616\n",
      "│    │    └─Residual: 3-49                              [1, 16, 128, 256]         8,240\n",
      "│    │    └─Conv2d: 3-50                                [1, 16, 128, 256]         2,320\n",
      "├─ResnetBlock: 1-8                                      [1, 16, 128, 256]         --\n",
      "│    └─Sequential: 2-22                                 [1, 32]                   --\n",
      "│    │    └─SiLU: 3-51                                  [1, 64]                   --\n",
      "│    │    └─Linear: 3-52                                [1, 32]                   2,080\n",
      "│    └─Block: 2-23                                      [1, 16, 128, 256]         --\n",
      "│    │    └─Conv2d: 3-53                                [1, 16, 128, 256]         4,624\n",
      "│    │    └─GroupNorm: 3-54                             [1, 16, 128, 256]         32\n",
      "│    │    └─SiLU: 3-55                                  [1, 16, 128, 256]         --\n",
      "│    └─Block: 2-24                                      [1, 16, 128, 256]         --\n",
      "│    │    └─Conv2d: 3-56                                [1, 16, 128, 256]         2,320\n",
      "│    │    └─GroupNorm: 3-57                             [1, 16, 128, 256]         32\n",
      "│    │    └─SiLU: 3-58                                  [1, 16, 128, 256]         --\n",
      "│    └─Conv2d: 2-25                                     [1, 16, 128, 256]         528\n",
      "├─Conv2d: 1-9                                           [1, 1, 128, 256]          17\n",
      "=========================================================================================================\n",
      "Total params: 2,432,785\n",
      "Trainable params: 2,432,785\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 4.39\n",
      "=========================================================================================================\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 482.10\n",
      "Params size (MB): 9.73\n",
      "Estimated Total Size (MB): 492.09\n",
      "=========================================================================================================\n",
      "FLOPs: 8.8166e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::lift_fresh\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::repeat\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::arange\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::sin\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::cos\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::silu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::var\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::rsqrt\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/oscar/home/voommen/apps/torch_env/lib64/python3.9/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    }
   ],
   "source": [
    "model = Unet2D(dim=16, Par=Par, dim_mults=(1, 2, 4, 8)).to(device).to(torch.float32)\n",
    "\n",
    "path_model = 'models/best_model.pt'\n",
    "model.load_state_dict(torch.load(path_model))\n",
    "\n",
    "print(summary(model, input_size=((1,)+x_train.shape[1:], (1,)) ) )\n",
    "\n",
    "# Adjust the dimensions as per your model's input size\n",
    "dummy_x = x_train_tensor[0:1].to(device)\n",
    "dummy_t = t_train_tensor[0:1].to(device)\n",
    "dummy_input = (dummy_x, dummy_t)\n",
    "\n",
    "# Profile the model\n",
    "model.eval()\n",
    "flops = 2 * torchprofile.profile_macs(model, dummy_input)\n",
    "print(f\"FLOPs: {flops:.4e}\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = CustomLoss(Par)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503d380-cbee-453b-86f0-219a5eb7a000",
   "metadata": {},
   "source": [
    "# Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53e1e13-db20-4609-b986-ebf4d1fc124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b245a644-9419-479c-a3ab-3649c194600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.01328\n",
      "Inference time: 0.01048\n",
      "Inference time: 0.01040\n",
      "Inference time: 0.01022\n",
      "Inference time: 0.01019\n",
      "Inference time: 0.01029\n",
      "Inference time: 0.01025\n",
      "Inference time: 0.01024\n",
      "Inference time: 0.01027\n",
      "Inference time: 0.01029\n",
      "Inference time: 0.01017\n",
      "Inference time: 0.01020\n",
      "Inference time: 0.01025\n",
      "Inference time: 0.01020\n",
      "Inference time: 0.01031\n",
      "\n",
      "mean: 0.010246634483337402\n"
     ]
    }
   ],
   "source": [
    "inference_time_ls = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i in range(15):\n",
    "    begin_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for x, t, y_true in test_data_loader:\n",
    "            y_pred = model(x.to(device), t.to(device))\n",
    "            break\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - begin_time\n",
    "    print(f\"Inference time: {inference_time:.5f}\")\n",
    "    inference_time_ls.append(inference_time)\n",
    "\n",
    "print()\n",
    "print(f\"mean: {np.mean(inference_time_ls[5:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc828015-8edc-46d3-b7fe-c95f10505665",
   "metadata": {},
   "source": [
    "# PeakVRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f503619-42b5-4bd3-8920-d77c22501d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak VRAM (allocated): 0.2898 GB\n",
      "Peak VRAM (reserved) : 0.7319 GB\n",
      "Config: batch=1, dtype= torch.float32 , device= cuda\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = False  # keep runs reproducible\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Warmup\n",
    "with torch.no_grad():\n",
    "    for x, t, y_true in test_data_loader:\n",
    "        _ = model(x.to(device), t.to(device))\n",
    "        break\n",
    "\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats() \n",
    "with torch.no_grad():\n",
    "    for x, t, y_true in test_data_loader:\n",
    "        _ = model(x.to(device), t.to(device))\n",
    "        break\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "# ---- Read peaks (bytes) and report in GB ----\n",
    "peak_alloc_GB   = torch.cuda.max_memory_allocated()  / 1e9\n",
    "peak_resvd_GB   = torch.cuda.max_memory_reserved()   / 1e9\n",
    "print(f\"Peak VRAM (allocated): {peak_alloc_GB:.4f} GB\")\n",
    "print(f\"Peak VRAM (reserved) : {peak_resvd_GB:.4f} GB\")\n",
    "print(\"Config: batch=1, dtype=\", DTYPE, \", device=\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de076564-f74d-47a7-83e9-4b689171c588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4515e-01\n",
      "TRAIN_TRUE: (76, 5, 128, 256), DTYPE: float32\n",
      "TRAIN_PRED: (76, 5, 128, 256), DTYPE: float32\n",
      "Val Loss: 1.4995e-01\n",
      "VAL_TRUE: (6, 5, 128, 256), DTYPE: float32\n",
      "VAL_PRED: (6, 5, 128, 256), DTYPE: float32\n",
      "Test Loss: 1.4307e-01\n",
      "TEST_TRUE: (6, 5, 128, 256), DTYPE: float32\n",
      "TEST_PRED: (6, 5, 128, 256), DTYPE: float32\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "\n",
    "y_true_ls = []\n",
    "y_pred_ls = []\n",
    "\n",
    "model.eval()\n",
    "train_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for x, t, y_true in train_loader:\n",
    "        with autocast():\n",
    "            y_pred = model(x.to(device), t.to(device))\n",
    "            loss   = criterion(y_pred, y_true.to(device))\n",
    "        train_loss += loss.item()\n",
    "        y_true_ls.append(y_true.detach().cpu().numpy())\n",
    "        y_pred_ls.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "train_loss /= len(train_loader)\n",
    "print(f\"Train Loss: {train_loss:.4e}\")\n",
    "\n",
    "TRAIN_TRUE = np.concatenate(y_true_ls, axis=0).reshape(-1, Par['lf'], Par['nx'], Par['ny']).astype(np.float32)\n",
    "TRAIN_PRED = np.concatenate(y_pred_ls, axis=0).reshape(-1, Par['lf'], Par['nx'], Par['ny']).astype(np.float32)\n",
    "\n",
    "print(f\"TRAIN_TRUE: {TRAIN_TRUE.shape}, DTYPE: {TRAIN_TRUE.dtype}\")\n",
    "print(f\"TRAIN_PRED: {TRAIN_PRED.shape}, DTYPE: {TRAIN_PRED.dtype}\")\n",
    "\n",
    "\n",
    "\n",
    "y_true_ls = []\n",
    "y_pred_ls = []\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for x, t, y_true in val_loader:\n",
    "        with autocast():\n",
    "            y_pred = model(x.to(device), t.to(device))\n",
    "            loss   = criterion(y_pred, y_true.to(device))\n",
    "        val_loss += loss.item()\n",
    "        y_true_ls.append(y_true.detach().cpu().numpy())\n",
    "        y_pred_ls.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "val_loss /= len(val_loader)\n",
    "print(f\"Val Loss: {val_loss:.4e}\")\n",
    "\n",
    "VAL_TRUE = np.concatenate(y_true_ls, axis=0).reshape(-1, Par['lf'], Par['nx'], Par['ny']).astype(np.float32)\n",
    "VAL_PRED = np.concatenate(y_pred_ls, axis=0).reshape(-1, Par['lf'], Par['nx'], Par['ny']).astype(np.float32)\n",
    "\n",
    "print(f\"VAL_TRUE: {VAL_TRUE.shape}, DTYPE: {VAL_TRUE.dtype}\")\n",
    "print(f\"VAL_PRED: {VAL_PRED.shape}, DTYPE: {VAL_PRED.dtype}\")\n",
    "\n",
    "\n",
    "\n",
    "y_true_ls = []\n",
    "y_pred_ls = []\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for x, t, y_true in test_loader:\n",
    "        with autocast():\n",
    "            y_pred = model(x.to(device), t.to(device))\n",
    "            loss   = criterion(y_pred, y_true.to(device))\n",
    "        test_loss += loss.item()\n",
    "        y_true_ls.append(y_true.detach().cpu().numpy())\n",
    "        y_pred_ls.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4e}\")\n",
    "\n",
    "TEST_TRUE = np.concatenate(y_true_ls, axis=0).reshape(-1, Par['lf'], Par['nx'], Par['ny']).astype(np.float32)\n",
    "TEST_PRED = np.concatenate(y_pred_ls, axis=0).reshape(-1, Par['lf'], Par['nx'], Par['ny']).astype(np.float32)\n",
    "\n",
    "print(f\"TEST_TRUE: {TEST_TRUE.shape}, DTYPE: {TEST_TRUE.dtype}\")\n",
    "print(f\"TEST_PRED: {TEST_PRED.shape}, DTYPE: {TEST_PRED.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214257f1-8717-4f61-a33e-b5b830e50a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"TRAIN_TRUE.npy\", TRAIN_TRUE)\n",
    "np.save(\"TRAIN_PRED.npy\", TRAIN_PRED)\n",
    "\n",
    "np.save(\"VAL_TRUE.npy\", VAL_TRUE)\n",
    "np.save(\"VAL_PRED.npy\", VAL_PRED)\n",
    "\n",
    "np.save(\"TEST_TRUE.npy\", TEST_TRUE)\n",
    "np.save(\"TEST_PRED.npy\", TEST_PRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bc2db-803b-4d33-bc08-a5234ffd0b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
